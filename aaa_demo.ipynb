{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411c59b3-f177-4a10-8925-d931ce572eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from insightface.app import FaceAnalysis\n",
    "from insightface.utils import face_align\n",
    "import torch\n",
    "from diffusers import StableDiffusionPipeline, DDIMScheduler, AutoencoderKL\n",
    "from PIL import Image\n",
    "from rembg import remove\n",
    "\n",
    "from ip_total.ip_adapter_total import IPAdapterTotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6dc69c-192d-4d74-8b1e-f0d9ccfbdb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_path = \"models\\majicmix-realistic-v7\" # pagebrain/majicmix-realistic-v7\n",
    "image_encoder_path_faceid = \"models/CLIP-ViT-H-14-laion2B-s32B-b79K\"\n",
    "image_encoder_path_general = \"models/image_encoder\"\n",
    "vae_model_path = \"models/sd-vae-ft-mse\"\n",
    "ip_total_ckpt = \"models/ip_total.bin\"\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ec542f-8474-4f38-9457-073425578073",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_grid(imgs, rows, cols):\n",
    "    assert len(imgs) == rows*cols\n",
    "\n",
    "    w, h = imgs[0].size\n",
    "    grid = Image.new('RGB', size=(cols*w, rows*h))\n",
    "    grid_w, grid_h = grid.size\n",
    "    \n",
    "    for i, img in enumerate(imgs):\n",
    "        grid.paste(img, box=(i%cols*w, i//cols*h))\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3849f9d0-5f68-4a49-9190-69dd50720cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load SD pipeline\n",
    "noise_scheduler = DDIMScheduler(\n",
    "        num_train_timesteps=1000,\n",
    "        beta_start=0.00085,\n",
    "        beta_end=0.012,\n",
    "        beta_schedule=\"scaled_linear\",\n",
    "        clip_sample=False,\n",
    "        set_alpha_to_one=False,\n",
    "        steps_offset=1,\n",
    ")\n",
    "vae  = AutoencoderKL.from_pretrained(vae_model_path).to(dtype=torch.float16)\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    base_model_path,\n",
    "    torch_dtype=torch.float16,\n",
    "    scheduler=noise_scheduler,\n",
    "    vae=vae,\n",
    "    feature_extractor=None,\n",
    "    safety_checker=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c63b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load ip-adapter\n",
    "ip_model = IPAdapterTotal(pipe, \n",
    "                          image_encoder_path_faceid=image_encoder_path_faceid,\n",
    "                          image_encoder_path_general=image_encoder_path_general,\n",
    "                          ip_ckpt=ip_total_ckpt,\n",
    "                          device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec09e937-3904-4d8e-a559-9066502ded36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess teplate images\n",
    "image_cloth = Image.open(\"data/input/cloth_img1.jpg\")\n",
    "image_cloth_rmbg = remove(image_cloth)\n",
    "image_cloth_rmbg = image_cloth_rmbg.convert(\"RGB\") #resize((256, 256))\n",
    "\n",
    "image_cloth_rmbg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa141df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess face image\n",
    "face_app = FaceAnalysis(name=\"buffalo_l\", providers=['CUDAExecutionProvider', 'CPUExecutionProvider'])\n",
    "face_app.prepare(ctx_id=0, det_size=(640, 640))\n",
    "\n",
    "img_path = \"data/input/face_img1.jpg\"\n",
    "image = cv2.imread(img_path)\n",
    "faces = face_app.get(image)\n",
    "\n",
    "faceid_embeds = torch.from_numpy(faces[0].normed_embedding).unsqueeze(0)\n",
    "face_image = face_align.norm_crop(image, landmark=faces[0].kps, image_size=224) # you can also segment the face\n",
    "face_image = cv2.cvtColor(face_image, cv2.COLOR_BGR2RGB)\n",
    "face_image = Image.fromarray(face_image)\n",
    "face_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23de3d2-169e-470b-8012-960e3d07b04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate\n",
    "prompt = \"photo of a beautiful girl wearing casual shirt in a bar\"\n",
    "negative_prompt = \"monochrome, lowres, bad anatomy, worst quality, low quality, blurry\"\n",
    "scale_faceid = 1.0\n",
    "scale_general = 1.0\n",
    "width=768\n",
    "height=768\n",
    "\n",
    "images = ip_model.generate(\n",
    "            prompt=prompt, negative_prompt=negative_prompt,\n",
    "            scale_faceid=scale_faceid, \n",
    "            scale_general=scale_general, \n",
    "            face_image=face_image, \n",
    "            faceid_embeds=faceid_embeds, \n",
    "            template_img=image_cloth_rmbg,\n",
    "            width=width, height=height, \n",
    "            num_samples=4,num_inference_steps=30, seed=21839\n",
    "        )\n",
    "\n",
    "# show result\n",
    "grid = image_grid(images, 1, 4)\n",
    "grid"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
